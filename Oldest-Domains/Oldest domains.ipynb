{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import string\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "domains = []\n",
    "\n",
    "for letter_1 in string.ascii_lowercase:\n",
    "    for letter_2 in string.ascii_lowercase:\n",
    "        domains.append(letter_1 + letter_2 + \".com\")\n",
    "        \n",
    "        for letter_3 in string.ascii_lowercase:\n",
    "            domains.append(letter_1 + letter_2 + letter_3 + \".com\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "domain_information = {}\n",
    "\n",
    "headers =    {\"Host\": \"reports.internic.net\",\n",
    "              \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; WOW64; rv:61.0) Gecko/20100101 Firefox/61.0\",\n",
    "              \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\",\n",
    "              \"Accept-Language\": \"en-US,en;q=0.5\",\n",
    "              \"Referer\": \"https://www.internic.net/\",\n",
    "              \"DNT\": \"1\",\n",
    "              \"Connection\": \"keep-alive\",\n",
    "              \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "\n",
    "domains_done = 0\n",
    "for domain_name in domains:\n",
    "    params = {\"whois_nic\": domain_name, \n",
    "              \"type\": \"domain\"}\n",
    "    \n",
    "    info = 0\n",
    "    \n",
    "    # Sometimes an empty webpage is returned\n",
    "    while len(info) < 100:\n",
    "        time.sleep(5)\n",
    "        \n",
    "        r = requests.get(\"https://reports.internic.net/cgi/whois\", \n",
    "                 params = params,\n",
    "                 headers = headers)\n",
    "        \n",
    "        soup = BeautifulSoup(r.text, \"html.parser\")\n",
    "        info = str(soup.findAll('pre'))\n",
    "    \n",
    "    creation_date = info[(info.find('Creation Date: ') + len('Creation Date: ')):info.find('\\r\\n   Registry Expiry Date:')]\n",
    "    expiration_date = info[(info.find('Registry Expiry Date: ') + len('Registry Expiry Date: ')):info.find('\\r\\n   Registrar: ')]\n",
    "    updated_date = info[(info.find('Updated Date: ') + len('Updated Date: ')):info.find('\\r\\n   Creation Date:')]\n",
    "    \n",
    "    # The Z denotes timezone UTC\n",
    "    if creation_date[-1] == \"Z\":\n",
    "        creation_date = creation_date[:-1]\n",
    "    if expiration_date[-1] == \"Z\":\n",
    "        expiration_date = expiration_date[:-1]\n",
    "    if updated_date[-1] == \"Z\":\n",
    "        updated_date = updated_date[:-1]\n",
    "    \n",
    "    try:\n",
    "        creation_date = datetime.datetime.strptime(creation_date, '%Y-%m-%dT%H:%M:%S')\n",
    "        expiration_date = datetime.datetime.strptime(expiration_date, '%Y-%m-%dT%H:%M:%S')\n",
    "        updated_date = datetime.datetime.strptime(updated_date, '%Y-%m-%dT%H:%M:%S')\n",
    "    except ValueError:\n",
    "        print(domain_name)\n",
    "    \n",
    "    domain_information[domain_name] = {\"Creation date\": creation_date,\n",
    "                                      \"Experation date\": expiration_date,\n",
    "                                      \"Update date\": updated_date}\n",
    "    \n",
    "    domains_done += 1\n",
    "    time.sleep(5)\n",
    "    \n",
    "    if domains_done % 100 == 0:\n",
    "        print(\"A total of {} domains is scraped, at {:0.3f} %\".format(domains_done, domains_done / len(domains) * 100))\n",
    "        \n",
    "        data = pd.DataFrame.from_dict(domain_information, orient = \"index\")\n",
    "        data.to_csv(\"Data\\Domain Information.csv\")\n",
    "    \n",
    "    data.to_csv(\"Data\\Domain Information.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sort_index()\n",
    "data.to_csv(\"Data\\Domain Information.csv\")\n",
    "data.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
